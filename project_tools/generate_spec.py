#!/usr/bin/env python3
"""
Enhanced SPEC File Generator for LLM Context
Extracts richer information from TypeScript/JavaScript projects.

Improvements over v1:
- Function/method signatures with parameters
- Class methods extraction
- JSDoc comment parsing
- TODO/FIXME extraction
- Import relationship mapping
- Key file content inclusion
- Route/endpoint detection
- Config file parsing

Usage:
    python generate_spec_v2.py /path/to/project
    python generate_spec_v2.py /path/to/project --include-snippets
    python generate_spec_v2.py /path/to/project --max-snippet-lines 30
"""

import argparse
import json
import os
import re
from pathlib import Path
from datetime import datetime
from typing import Optional
from dataclasses import dataclass, field


# =============================================================================
# Configuration
# =============================================================================

DEFAULT_IGNORE = {
    'node_modules', '.git', 'dist', 'build', '.vscode', '.idea',
    '__pycache__', '.DS_Store', 'coverage', '.nyc_output', 'logs',
    '.cache', '.parcel-cache', '.next', '.nuxt'
}

CODE_EXTENSIONS = {'.ts', '.js', '.tsx', '.jsx', '.mjs', '.cjs'}
CONFIG_FILES = {'package.json', 'tsconfig.json', 'vite.config.ts', 'vite.config.js'}
ENTRY_POINTS = {'index.ts', 'index.js', 'main.ts', 'main.js', 'app.ts', 'app.js'}

# Priority files to always include snippets from
PRIORITY_PATTERNS = [
    r'routes?[./]',
    r'config[./]',
    r'app\.(ts|js)$',
    r'index\.(ts|js)$',
    r'server\.(ts|js)$',
]


# =============================================================================
# Enhanced Regex Patterns
# =============================================================================

PATTERNS = {
    # Exports with full signatures
    'export_function': re.compile(
        r'export\s+(?:async\s+)?function\s+(\w+)\s*(\([^)]*\))(?:\s*:\s*([^\n{]+))?',
        re.MULTILINE
    ),
    'export_arrow': re.compile(
        r'export\s+const\s+(\w+)\s*=\s*(?:async\s*)?\(([^)]*)\)\s*(?::\s*([^\n=]+))?\s*=>',
        re.MULTILINE
    ),
    'export_class': re.compile(
        r'export\s+(?:default\s+)?class\s+(\w+)(?:\s+extends\s+([\w.]+))?(?:\s+implements\s+([\w,\s]+))?',
        re.MULTILINE
    ),
    'export_interface': re.compile(
        r'export\s+(?:interface|type)\s+(\w+)(?:<[^>]+>)?(?:\s*=\s*|\s*\{)',
        re.MULTILINE
    ),
    'export_const': re.compile(
        r'export\s+const\s+(\w+)\s*(?::\s*([^\n=]+))?\s*=',
        re.MULTILINE
    ),
    
    # Class internals
    'class_method': re.compile(
        r'^\s+(?:async\s+)?(\w+)\s*(\([^)]*\))(?:\s*:\s*([^\n{]+))?\s*\{',
        re.MULTILINE
    ),
    'class_property': re.compile(
        r'^\s+(?:private|public|protected|readonly)?\s*(\w+)\s*(?:\?)?:\s*([^\n;=]+)',
        re.MULTILINE
    ),
    
    # Imports
    'import_named': re.compile(
        r'import\s+\{([^}]+)\}\s+from\s+[\'"]([^\'"]+)[\'"]'
    ),
    'import_default': re.compile(
        r'import\s+(\w+)\s+from\s+[\'"]([^\'"]+)[\'"]'
    ),
    'import_all': re.compile(
        r'import\s+\*\s+as\s+(\w+)\s+from\s+[\'"]([^\'"]+)[\'"]'
    ),
    
    # Routes (Express-style)
    'express_route': re.compile(
        r'\.(get|post|put|patch|delete|use)\s*\(\s*[\'"]([^\'"]+)[\'"]',
        re.IGNORECASE
    ),
    
    # Comments
    'jsdoc': re.compile(
        r'/\*\*\s*(.*?)\s*\*/',
        re.DOTALL
    ),
    'todo': re.compile(
        r'(?://|/\*)\s*(TODO|FIXME|BUG|HACK|XXX)[\s:]+(.+?)(?:\*/|$)',
        re.IGNORECASE | re.MULTILINE
    ),
}


# =============================================================================
# Data Classes
# =============================================================================

@dataclass
class FunctionInfo:
    name: str
    params: str = ""
    return_type: str = ""
    jsdoc: str = ""
    is_async: bool = False


@dataclass 
class ClassInfo:
    name: str
    extends: str = ""
    implements: str = ""
    methods: list = field(default_factory=list)
    properties: list = field(default_factory=list)
    jsdoc: str = ""


@dataclass
class ImportInfo:
    module: str
    items: list = field(default_factory=list)
    is_relative: bool = False


@dataclass
class FileInfo:
    path: Path
    relative_path: str
    exports: list = field(default_factory=list)
    functions: list = field(default_factory=list)
    classes: list = field(default_factory=list)
    interfaces: list = field(default_factory=list)
    imports: list = field(default_factory=list)
    routes: list = field(default_factory=list)
    todos: list = field(default_factory=list)
    line_count: int = 0
    description: str = ""
    is_entry_point: bool = False
    is_priority: bool = False


@dataclass
class ProjectSpec:
    root: Path
    name: str
    files: list = field(default_factory=list)
    structure: str = ""
    config: dict = field(default_factory=dict)
    dependency_graph: dict = field(default_factory=dict)
    all_routes: list = field(default_factory=list)
    all_todos: list = field(default_factory=list)
    generated_at: str = ""


# =============================================================================
# Extraction Functions
# =============================================================================

def clean_jsdoc(jsdoc: str) -> str:
    """Clean up JSDoc comment formatting."""
    if not jsdoc:
        return ""
    # Remove * at start of lines
    lines = jsdoc.split('\n')
    cleaned = []
    for line in lines:
        line = re.sub(r'^\s*\*\s?', '', line).strip()
        if line and not line.startswith('@'):
            cleaned.append(line)
    return ' '.join(cleaned)[:300]


def extract_jsdoc_before(content: str, pos: int) -> str:
    """Extract JSDoc comment that appears before a given position."""
    # Look backwards from position for /** ... */
    before = content[:pos]
    match = re.search(r'/\*\*\s*(.*?)\s*\*/\s*$', before, re.DOTALL)
    if match:
        return clean_jsdoc(match.group(1))
    return ""


def extract_class_details(content: str, class_match) -> ClassInfo:
    """Extract methods and properties from a class definition."""
    class_name = class_match.group(1)
    extends = class_match.group(2) or ""
    implements = class_match.group(3) or ""
    
    # Find the class body (simplified - looks for matching braces)
    start = class_match.end()
    brace_count = 0
    class_body = ""
    in_class = False
    
    for i, char in enumerate(content[start:], start):
        if char == '{':
            brace_count += 1
            in_class = True
        elif char == '}':
            brace_count -= 1
        
        if in_class:
            class_body += char
            
        if in_class and brace_count == 0:
            break
    
    # Extract methods
    methods = []
    for match in PATTERNS['class_method'].finditer(class_body):
        method_name = match.group(1)
        if method_name not in ('constructor', 'if', 'for', 'while', 'switch'):
            params = match.group(2) or "()"
            return_type = (match.group(3) or "").strip()
            methods.append(FunctionInfo(
                name=method_name,
                params=params,
                return_type=return_type
            ))
    
    # Extract properties
    properties = []
    for match in PATTERNS['class_property'].finditer(class_body):
        prop_name = match.group(1)
        prop_type = (match.group(2) or "").strip()
        if prop_name not in ('if', 'for', 'return'):
            properties.append((prop_name, prop_type))
    
    jsdoc = extract_jsdoc_before(content, class_match.start())
    
    return ClassInfo(
        name=class_name,
        extends=extends,
        implements=implements.strip(),
        methods=methods[:10],  # Limit to first 10
        properties=properties[:10],
        jsdoc=jsdoc
    )


def extract_file_info(file_path: Path, root: Path) -> Optional[FileInfo]:
    """Extract comprehensive info from a JS/TS file."""
    try:
        content = file_path.read_text(encoding='utf-8', errors='ignore')
    except Exception:
        return None
    
    relative = str(file_path.relative_to(root))
    
    info = FileInfo(
        path=file_path,
        relative_path=relative,
        line_count=len(content.splitlines()),
        is_entry_point=file_path.name in ENTRY_POINTS,
        is_priority=any(re.search(p, relative) for p in PRIORITY_PATTERNS)
    )
    
    # File description from first JSDoc
    jsdoc_match = PATTERNS['jsdoc'].search(content)
    if jsdoc_match:
        info.description = clean_jsdoc(jsdoc_match.group(1))
    
    # Extract exported functions with signatures
    for match in PATTERNS['export_function'].finditer(content):
        fn = FunctionInfo(
            name=match.group(1),
            params=match.group(2) or "()",
            return_type=(match.group(3) or "").strip(),
            jsdoc=extract_jsdoc_before(content, match.start()),
            is_async='async' in match.group(0)
        )
        info.functions.append(fn)
        info.exports.append(fn.name)
    
    # Arrow function exports
    for match in PATTERNS['export_arrow'].finditer(content):
        fn = FunctionInfo(
            name=match.group(1),
            params=f"({match.group(2)})" if match.group(2) else "()",
            return_type=(match.group(3) or "").strip(),
            jsdoc=extract_jsdoc_before(content, match.start())
        )
        info.functions.append(fn)
        info.exports.append(fn.name)
    
    # Classes with methods
    for match in PATTERNS['export_class'].finditer(content):
        class_info = extract_class_details(content, match)
        info.classes.append(class_info)
        info.exports.append(class_info.name)
    
    # Interfaces/Types
    for match in PATTERNS['export_interface'].finditer(content):
        info.interfaces.append(match.group(1))
        info.exports.append(match.group(1))
    
    # Const exports (non-function)
    for match in PATTERNS['export_const'].finditer(content):
        name = match.group(1)
        if name not in info.exports:
            info.exports.append(name)
    
    # Imports
    for pattern_name in ('import_named', 'import_default', 'import_all'):
        for match in PATTERNS[pattern_name].finditer(content):
            module = match.group(2) if pattern_name == 'import_named' else match.group(2) if len(match.groups()) > 1 else match.group(1)
            items = []
            if pattern_name == 'import_named':
                items = [i.strip().split(' as ')[0] for i in match.group(1).split(',')]
            
            info.imports.append(ImportInfo(
                module=module,
                items=items,
                is_relative=module.startswith('.')
            ))
    
    # Routes
    for match in PATTERNS['express_route'].finditer(content):
        method = match.group(1).upper()
        path = match.group(2)
        info.routes.append(f"{method} {path}")
    
    # TODOs
    for match in PATTERNS['todo'].finditer(content):
        tag = match.group(1).upper()
        text = match.group(2).strip()[:100]
        info.todos.append(f"{tag}: {text}")
    
    return info


def parse_package_json(root: Path) -> dict:
    """Extract relevant info from package.json."""
    pkg_path = root / 'package.json'
    if not pkg_path.exists():
        return {}
    
    try:
        with open(pkg_path) as f:
            pkg = json.load(f)
        return {
            'name': pkg.get('name', ''),
            'description': pkg.get('description', ''),
            'scripts': pkg.get('scripts', {}),
            'dependencies': list(pkg.get('dependencies', {}).keys()),
            'devDependencies': list(pkg.get('devDependencies', {}).keys()),
        }
    except Exception:
        return {}


def build_dependency_graph(files: list) -> dict:
    """Build a map of which files import which."""
    graph = {}
    
    for file in files:
        importers = []
        for other in files:
            if other.relative_path == file.relative_path:
                continue
            for imp in other.imports:
                if imp.is_relative:
                    # Simplified matching - check if import path could match this file
                    if file.path.stem in imp.module or file.relative_path.replace('\\', '/') in imp.module:
                        importers.append(other.relative_path)
                        break
        if importers:
            graph[file.relative_path] = importers
    
    return graph


# =============================================================================
# Tree Generation
# =============================================================================

def generate_tree(root: Path, ignore_patterns: set, max_depth: int = 4, prefix: str = "") -> str:
    """Generate directory tree structure."""
    if max_depth < 0:
        return ""
    
    try:
        entries = sorted(root.iterdir(), key=lambda x: (x.is_file(), x.name.lower()))
    except PermissionError:
        return ""
    
    entries = [e for e in entries if e.name not in ignore_patterns and not e.name.startswith('.')]
    tree_str = ""
    
    for i, entry in enumerate(entries):
        is_last = i == len(entries) - 1
        connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
        
        if entry.is_file():
            tree_str += f"{prefix}{connector}{entry.name}\n"
        else:
            tree_str += f"{prefix}{connector}{entry.name}/\n"
            extension = "    " if is_last else "â”‚   "
            tree_str += generate_tree(entry, ignore_patterns, max_depth - 1, prefix + extension)
    
    return tree_str


# =============================================================================
# Markdown Generation
# =============================================================================

def format_function(fn: FunctionInfo, indent: str = "") -> str:
    """Format a function with its signature."""
    async_prefix = "async " if fn.is_async else ""
    ret = f" â†’ {fn.return_type}" if fn.return_type else ""
    sig = f"{indent}- `{async_prefix}{fn.name}{fn.params}{ret}`"
    if fn.jsdoc:
        sig += f"\n{indent}  _{fn.jsdoc}_"
    return sig


def format_class(cls: ClassInfo) -> str:
    """Format a class with its methods."""
    lines = []
    
    # Class declaration
    decl = f"**class {cls.name}**"
    if cls.extends:
        decl += f" extends `{cls.extends}`"
    if cls.implements:
        decl += f" implements `{cls.implements}`"
    lines.append(decl)
    
    if cls.jsdoc:
        lines.append(f"_{cls.jsdoc}_")
    
    # Properties
    if cls.properties:
        props = [f"`{name}: {type_}`" for name, type_ in cls.properties[:5]]
        lines.append(f"Properties: {', '.join(props)}")
    
    # Methods
    if cls.methods:
        lines.append("Methods:")
        for method in cls.methods[:8]:
            ret = f" â†’ {method.return_type}" if method.return_type else ""
            lines.append(f"  - `{method.name}{method.params}{ret}`")
    
    return '\n'.join(lines)


def generate_spec(project: ProjectSpec, include_snippets: bool = False, max_snippet_lines: int = 50) -> str:
    """Generate the enhanced SPEC markdown content."""
    lines = [
        f"# {project.name} - Project Specification",
        "",
        f"> Generated: {project.generated_at}",
        "",
    ]
    
    # Project info from package.json
    if project.config:
        if project.config.get('description'):
            lines.extend([
                f"**{project.config['description']}**",
                "",
            ])
        
        if project.config.get('scripts'):
            lines.extend([
                "## Scripts",
                "",
                "| Command | Action |",
                "|---------|--------|",
            ])
            for name, cmd in list(project.config['scripts'].items())[:10]:
                lines.append(f"| `npm run {name}` | `{cmd[:50]}{'...' if len(cmd) > 50 else ''}` |")
            lines.append("")
    
    # Directory structure
    lines.extend([
        "## Directory Structure",
        "",
        "```",
        f"{project.name}/",
        project.structure,
        "```",
        "",
    ])
    
    # Stats
    total_lines = sum(f.line_count for f in project.files)
    lines.extend([
        "## Overview",
        "",
        f"- **Files:** {len(project.files)}",
        f"- **Lines:** {total_lines:,}",
        f"- **Routes:** {len(project.all_routes)}",
        f"- **TODOs:** {len(project.all_todos)}",
        "",
    ])
    
    # Routes summary
    if project.all_routes:
        lines.extend([
            "## API Routes",
            "",
        ])
        for route in project.all_routes[:50]:
            lines.append(f"- `{route}`")
        if len(project.all_routes) > 50:
            lines.append(f"- ... and {len(project.all_routes) - 50} more")
        lines.append("")
    
    # TODOs
    if project.all_todos:
        lines.extend([
            "## Active TODOs",
            "",
        ])
        for todo in project.all_todos[:15]:
            lines.append(f"- {todo}")
        if len(project.all_todos) > 15:
            lines.append(f"- ... and {len(project.all_todos) - 15} more")
        lines.append("")
    
    # Group files by directory
    dirs: dict[str, list[FileInfo]] = {}
    for file in project.files:
        dir_path = str(Path(file.relative_path).parent)
        if dir_path not in dirs:
            dirs[dir_path] = []
        dirs[dir_path].append(file)
    
    # Module documentation
    lines.extend([
        "## Modules",
        "",
    ])
    
    for dir_path in sorted(dirs.keys()):
        dir_files = dirs[dir_path]
        dir_name = dir_path if dir_path != '.' else 'Root'
        
        lines.extend([
            f"### ðŸ“ {dir_name}",
            "",
        ])
        
        for file in sorted(dir_files, key=lambda f: (not f.is_entry_point, f.relative_path)):
            # File header
            icon = "â­" if file.is_entry_point else "ðŸ“„"
            lines.append(f"#### {icon} `{Path(file.relative_path).name}` ({file.line_count} lines)")
            lines.append("")
            
            if file.description:
                lines.append(f"_{file.description}_")
                lines.append("")
            
            # Classes with methods
            if file.classes:
                for cls in file.classes:
                    lines.append(format_class(cls))
                    lines.append("")
            
            # Standalone functions
            standalone_fns = [fn for fn in file.functions 
                           if not any(fn.name in [m.name for m in cls.methods] for cls in file.classes)]
            if standalone_fns:
                lines.append("**Functions:**")
                for fn in standalone_fns[:10]:
                    lines.append(format_function(fn))
                if len(standalone_fns) > 10:
                    lines.append(f"  - ... +{len(standalone_fns) - 10} more")
                lines.append("")
            
            # Interfaces
            if file.interfaces:
                lines.append(f"**Types:** `{', '.join(file.interfaces[:10])}`")
                lines.append("")
            
            # External imports only
            external = [imp.module for imp in file.imports if not imp.is_relative]
            if external:
                lines.append(f"**Dependencies:** `{', '.join(external[:8])}`")
                lines.append("")
            
            # File-specific routes
            if file.routes:
                lines.append(f"**Routes:** `{', '.join(file.routes[:5])}`")
                lines.append("")
    
    # Dependency summary
    if project.config.get('dependencies'):
        lines.extend([
            "## External Dependencies",
            "",
            ", ".join(sorted(project.config['dependencies'])),
            "",
        ])
    
    # Import graph for key files
    if project.dependency_graph:
        lines.extend([
            "## Internal Dependencies",
            "",
            "Files and what imports them:",
            "",
        ])
        for file_path, importers in sorted(project.dependency_graph.items())[:15]:
            lines.append(f"- `{file_path}` â† {', '.join(f'`{i}`' for i in importers[:3])}")
        lines.append("")
    
    return '\n'.join(lines)


# =============================================================================
# Main
# =============================================================================

def scan_project(root: Path, ignore_patterns: set) -> list[FileInfo]:
    """Scan project and extract info from all code files."""
    files = []
    
    for file_path in root.rglob('*'):
        if file_path.is_file() and not any(p in file_path.parts for p in ignore_patterns):
            if file_path.suffix in CODE_EXTENSIONS:
                info = extract_file_info(file_path, root)
                if info:
                    files.append(info)
    
    files.sort(key=lambda x: x.relative_path)
    return files


def main():
    parser = argparse.ArgumentParser(
        description="Generate enhanced SPEC.md for LLM context"
    )
    parser.add_argument("path", help="Project root directory")
    parser.add_argument("-o", "--output", default="SPEC.md", help="Output file name")
    parser.add_argument("-d", "--depth", type=int, default=4, help="Tree depth")
    parser.add_argument("--ignore", nargs="*", default=[], help="Additional dirs to ignore")
    parser.add_argument("--stdout", action="store_true", help="Print to stdout")
    parser.add_argument("--include-snippets", action="store_true", help="Include code snippets from key files")
    parser.add_argument("--max-snippet-lines", type=int, default=50, help="Max lines per snippet")
    
    args = parser.parse_args()
    
    root = Path(args.path).resolve()
    if not root.exists():
        print(f"Error: Path '{root}' does not exist")
        return 1
    
    ignore_patterns = DEFAULT_IGNORE | set(args.ignore)
    
    print(f"Scanning {root}...")
    
    # Build project spec
    project = ProjectSpec(
        root=root,
        name=root.name,
        generated_at=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        config=parse_package_json(root)
    )
    
    project.structure = generate_tree(root, ignore_patterns, args.depth)
    project.files = scan_project(root, ignore_patterns)
    project.dependency_graph = build_dependency_graph(project.files)
    
    # Collect all routes and TODOs
    for file in project.files:
        for route in file.routes:
            project.all_routes.append(f"{route} ({file.relative_path})")
        for todo in file.todos:
            project.all_todos.append(f"{todo} ({Path(file.relative_path).name})")
    
    print(f"Found {len(project.files)} code files")
    print(f"Found {len(project.all_routes)} routes")
    print(f"Found {len(project.all_todos)} TODOs")
    
    spec_content = generate_spec(project, args.include_snippets, args.max_snippet_lines)
    
    if args.stdout:
        print(spec_content)
    else:
        output_path = root / args.output
        output_path.write_text(spec_content, encoding='utf-8')
        print(f"Generated: {output_path}")
        print(f"Size: {len(spec_content):,} characters")
    
    return 0


if __name__ == "__main__":
    exit(main())